{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ad571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re  # used for preprocessing\n",
    "import nltk  # Natural Language Toolkit, used for preprocessing\n",
    "import string #used for preprocessing\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08003c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  tweet_id   author_id inbound                      created_at  \\\n",
       "0          0         1  sprintcare   False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1          1         2      115712    True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2          2         3      115712    True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3          3         4  sprintcare   False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4          4         5      115712    True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_whole = pd.read_csv(\"/home/mona/python_notebooks/data-visualization-main/twcs.csv\", nrows=5000)\n",
    "df = df_whole[[\"text\"]]\n",
    "df_whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f0c0f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAD6CAYAAACPpxFEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAW8ElEQVR4nO3df5BdZ33f8fcHGWR+ebCrtavoRyQYAZEZE+xFdUtDASe1IMQy7XiqzlA0iRs1jJJC0xQsyAD9gxmapkCY1G4EOMhA7IqfVpk4RSgUT2cwygpsbFkoFsixhRRLlGFsEkaOzbd/3LNws75aXZ3d+2O179fMzj3ne55zz1fPaPXVc55zn5uqQpKks/W0UScgSVqYLCCSpFYsIJKkViwgkqRWLCCSpFYsIJKkVgZWQJLcnOREkvtmxH8ryaEkB5L8Xld8e5LDzbGru+JXJLm3OfahJBlUzpKk/p03wPf+GPCHwC3TgSSvBjYBl1XVqSQXN/H1wGbgUuBngC8leWFVPQncBGwF7gL+FNgI3HGmiy9btqzWrFkzn38eSTrn7d+//3tVNdFP24EVkKq6M8maGeE3A++rqlNNmxNNfBNwWxM/kuQwsCHJg8AFVfVVgCS3ANfSRwFZs2YNU1NT8/FHkaRFI8lf9dt22HMgLwR+IcnXknwlycub+Arg4a52R5vYimZ7ZrynJFuTTCWZOnny5DynLknqNuwCch5wIXAl8J+AXc2cRq95jZol3lNV7aiqyaqanJjoawQmSWpp2AXkKPDZ6tgH/BhY1sRXdbVbCRxr4it7xCVJIzbsAvJ54DUASV4IPAP4HrAb2JxkaZK1wDpgX1UdBx5LcmUzUnkTcPuQc5Yk9TCwSfQktwKvApYlOQq8G7gZuLl5tPdxYEt1lgM+kGQXcD/wBLCteQILOhPvHwOeSWfy/IwT6JKkwcu5upz75ORk+RSWJJ2dJPurarKftn4SXZLUigVEktSKBUSS1MoglzKRzmyUS5udo/N/0rA4ApEktWIBkSS1YgGRJLViAZEktWIBkSS1YgGRJLViAZEktWIBkSS1YgGRJLViAZEktWIBkSS1YgGRJLViAZEkteJqvOoY5aq4khakgY1Aktyc5ETz/eczj/1OkkqyrCu2PcnhJIeSXN0VvyLJvc2xDyX+SydJ42CQt7A+BmycGUyyCvgl4KGu2HpgM3Bpc86NSZY0h28CtgLrmp+nvKckafgGVkCq6k7g+z0OfQB4G9D9bT6bgNuq6lRVHQEOAxuSLAcuqKqvVlUBtwDXDipnSVL/hjqJnuQa4LtVdc+MQyuAh7v2jzaxFc32zPjp3n9rkqkkUydPnpynrCVJvQytgCR5FvBO4F29DveI1SzxnqpqR1VNVtXkxMREu0QlSX0Z5lNYLwDWAvc08+Arga8n2UBnZLGqq+1K4FgTX9kjLkkasaGNQKrq3qq6uKrWVNUaOsXh8qr6a2A3sDnJ0iRr6UyW76uq48BjSa5snr56E3D7sHKWJJ3eIB/jvRX4KvCiJEeTXH+6tlV1ANgF3A/8GbCtqp5sDr8Z+AidifVvA3cMKmdJUv/Sebjp3DM5OVlTU1OjTmPhWIwfrzlH/+5Lc5Fkf1VN9tPWpUwkSa1YQCRJrVhAJEmtWEAkSa1YQCRJrVhAJEmtWEAkSa1YQCRJrVhAJEmtWEAkSa1YQCRJrVhAJEmtWEAkSa1YQCRJrVhAJEmtWEAkSa1YQCRJrVhAJEmtDPI70W9OciLJfV2x/5rkW0m+meRzSZ7XdWx7ksNJDiW5uit+RZJ7m2MfShbjd69K0vgZ5AjkY8DGGbE9wEuq6jLgL4HtAEnWA5uBS5tzbkyypDnnJmArsK75mfmekqQRGFgBqao7ge/PiH2xqp5odu8CVjbbm4DbqupUVR0BDgMbkiwHLqiqr1ZVAbcA1w4qZ0lS/0Y5B/JrwB3N9grg4a5jR5vYimZ7ZrynJFuTTCWZOnny5DynK0nqNpICkuSdwBPAJ6dDPZrVLPGeqmpHVU1W1eTExMTcE5UkndZ5w75gki3A64GrmttS0BlZrOpqthI41sRX9ohLkkZsqCOQJBuBtwPXVNXfdh3aDWxOsjTJWjqT5fuq6jjwWJIrm6ev3gTcPsycJUm9DWwEkuRW4FXAsiRHgXfTeepqKbCneRr3rqr6jao6kGQXcD+dW1vbqurJ5q3eTOeJrmfSmTO5A0nSyOWnd5HOLZOTkzU1NTXqNBaOxfjxmnP07740F0n2V9VkP239JLokqRULiCSpFQuIJKkVC4gkqRULiCSpFQuIJKkVC4gkqRULiCSpFQuIJKkVC4gkqRULiCSpFQuIJKkVC4gkqZWhf6GUZrEYV8SVtGA5ApEktWIBkSS1YgGRJLViAZEktTKwApLk5iQnktzXFbsoyZ4kDzSvF3Yd257kcJJDSa7uil+R5N7m2IcSZ5olaRwMcgTyMWDjjNgNwN6qWgfsbfZJsh7YDFzanHNjkiXNOTcBW4F1zc/M95QkjcDACkhV3Ql8f0Z4E7Cz2d4JXNsVv62qTlXVEeAwsCHJcuCCqvpqVRVwS9c5kqQRGvYcyCVVdRygeb24ia8AHu5qd7SJrWi2Z8Z7SrI1yVSSqZMnT85r4pKkv29cJtF7zWvULPGeqmpHVU1W1eTExMS8JSdJeqphF5BHmttSNK8nmvhRYFVXu5XAsSa+skdckjRifRWQJC+Zp+vtBrY021uA27vim5MsTbKWzmT5vuY212NJrmyevnpT1zmSpBHqdy2s/5HkGXSerPqTqvrBmU5IcivwKmBZkqPAu4H3AbuSXA88BFwHUFUHkuwC7geeALZV1ZPNW725ue4zgTuaH0nSiKXzcFMfDZN1wK/R+Ud/H/DHVbVngLnNyeTkZE1NTY06jbPjR1yGq8+/+9JikmR/VU3207bvOZCqegD4XeDtwD8DPpTkW0n+Rbs0JUkLWb9zIJcl+QBwEHgN8CtV9XPN9gcGmJ8kaUz1Owfyh8CHgXdU1Y+mg1V1LMnvDiQzSdJY67eAvA740fTEdpKnAedX1d9W1ccHlp0kaWz1OwfyJTpPQU17VhOTJC1S/RaQ86vqh9M7zfazBpOSJGkh6LeA/E2Sy6d3klwB/GiW9pKkc1y/cyBvBT6VZHoZkeXAvxpIRpKkBaGvAlJVf5HkxcCL6Cxw+K2q+ruBZiZJGmv9jkAAXg6sac55WRKq6paBZCVJGnt9FZAkHwdeANwNTK9RNf0FT5KkRajfEcgksL76XThLknTO6/cprPuAfzjIRCRJC0u/I5BlwP1J9gGnpoNVdc1AspIkjb1+C8h7BpmEJGnh6fcx3q8k+VlgXVV9KcmzgCWDTU2SNM76Xc7914FPA3/UhFYAnx9QTpKkBaDfSfRtwCuAR+EnXy518aCSkiSNv34LyKmqenx6J8l5dD4H0kqS/5DkQJL7ktya5PwkFyXZk+SB5vXCrvbbkxxOcijJ1W2vK0maP/0WkK8keQfwzCS/BHwK+F9tLphkBfDvgcmqegmduZTNwA3A3qpaB+xt9kmyvjl+KbARuDGJ8y+SNGL9FpAbgJPAvcC/A/6Uzvejt3UenWJ0Hp1l4Y8Bm4CdzfGdwLXN9ibgtqo6VVVHgMPAhjlcW5I0D/p9CuvHdL7S9sNzvWBVfTfJ7wMP0VkS/otV9cUkl1TV8abN8STTcywrgLu63uJoE3uKJFuBrQCrV6+ea6qSpFn0+xTWkSTfmfnT5oLN3MYmYC3wM8Czk7xxtlN6xHrOv1TVjqqarKrJiYmJNulJkvp0NmthTTsfuA64qOU1fxE4UlUnAZJ8FvgnwCNJljejj+XAiab9UWBV1/kr6dzykiSNUF8jkKr6f10/362qDwKvaXnNh4ArkzwrSYCrgIPAbmBL02YLcHuzvRvYnGRpkrXAOmBfy2tLkuZJv8u5X961+zQ6I5LntrlgVX0tyaeBrwNPAN8AdgDPAXYluZ5OkbmuaX8gyS7g/qb9tqp6suebS5KGJv2s0J7ky127TwAPAr9fVYcGlNecTU5O1tTU1KjTODvpNd2jgfHbCaSnSLK/qibP3LL/p7BePbeUJEnnmn5vYf32bMer6v3zk44kaaE4m6ewXk5nQhvgV4A7gYcHkZQkafydzRdKXV5VjwEkeQ/wqar6t4NKTJI03vpdymQ18HjX/uPAmnnPRpK0YPQ7Avk4sC/J5+h8CvwNwC0Dy0qSNPb6fQrrvUnuAH6hCf1qVX1jcGlJksZdv7ewoLNq7qNV9QfA0eZT4ZKkRarfxRTfDbwd2N6Eng58YlBJSZLGX78jkDcA1wB/A1BVx2i5lIkk6dzQbwF5vDprnhRAkmcPLiVJ0kLQbwHZleSPgOcl+XXgS8zDl0tJkhauMz6F1Sy5/j+BFwOPAi8C3lVVewacmyRpjJ2xgFRVJfl8VV0BWDQkSUD/t7DuSvLygWYiSVpQ+v0k+quB30jyIJ0nsUJncHLZoBKTJI23WQtIktVV9RDw2iHlI0laIM40Avk8nVV4/yrJZ6rqXw4hJ0nSAnCmOZDu71h9/nxdNMnzknw6ybeSHEzyj5NclGRPkgea1wu72m9PcjjJoSRXz1cekqT2zlRA6jTbc/UHwJ9V1YuBlwIHgRuAvVW1Dtjb7JNkPbAZuBTYCNyYZMk85iJJauFMBeSlSR5N8hhwWbP9aJLHkjza5oJJLgBeCXwUoKoer6ofAJuAnU2zncC1zfYm4LaqOlVVR4DDwIY215YkzZ9Z50CqahD/038+cBL44yQvBfYDbwEuqarjzXWPJ7m4ab8CuKvr/KNN7CmSbAW2AqxevXoAqUuSpp3Ncu7z5TzgcuCmqnoZnceCb5ilfXrEet5Oq6odVTVZVZMTExNzz1SSdFqjKCBHgaNV9bVm/9N0CsojSZYDNK8nutqv6jp/JXBsSLlKkk5j6AWkqv4aeDjJi5rQVcD9wG5gSxPbAtzebO8GNidZ2nyJ1Tpg3xBTliT10O8n0efbbwGfTPIM4DvAr9IpZruSXA88BFwHUFUHkuyiU2SeALZV1ZOjSVuSNG0kBaSq7gYmexy66jTt3wu8d5A5SZLOzijmQCRJ5wALiCSpFQuIJKkVC4gkqRULiCSplVE9xjve0uvD75Kkbo5AJEmtWEAkSa1YQCRJrVhAJEmtWEAkSa1YQCRJrVhAJEmtWEAkSa1YQCRJrVhAJEmtWEAkSa1YQCRJrYysgCRZkuQbSb7Q7F+UZE+SB5rXC7vabk9yOMmhJFePKmdJ0k+NcgTyFuBg1/4NwN6qWgfsbfZJsh7YDFwKbARuTLJkyLlKkmYYSQFJshL4ZeAjXeFNwM5meydwbVf8tqo6VVVHgMPAhiGlKkk6jVGNQD4IvA34cVfskqo6DtC8XtzEVwAPd7U72sSeIsnWJFNJpk6ePDnvSUuSfmroBSTJ64ETVbW/31N6xKpXw6raUVWTVTU5MTHROkdJ0pmN4hsJXwFck+R1wPnABUk+ATySZHlVHU+yHDjRtD8KrOo6fyVwbKgZS5KeYugjkKraXlUrq2oNncnxP6+qNwK7gS1Nsy3A7c32bmBzkqVJ1gLrgH1DTluSNMM4fSf6+4BdSa4HHgKuA6iqA0l2AfcDTwDbqurJ0aUpSQJIVc/phAVvcnKypqam2p2cXtMuOueco3/3pblIsr+qJvtp6yfRJUmtWEAkSa1YQCRJrVhAJEmtWEAkSa1YQCRJrVhAJEmtWEAkSa1YQCRJrVhAJEmtWEAkSa1YQCRJrVhAJEmtWEAkSa1YQCRJrVhAJEmtWEAkSa1YQCRJrQy9gCRZleTLSQ4mOZDkLU38oiR7kjzQvF7Ydc72JIeTHEpy9bBzliQ91ShGIE8A/7Gqfg64EtiWZD1wA7C3qtYBe5t9mmObgUuBjcCNSZaMIG9JUpehF5CqOl5VX2+2HwMOAiuATcDOptlO4NpmexNwW1WdqqojwGFgw1CTliQ9xXmjvHiSNcDLgK8Bl1TVcegUmSQXN81WAHd1nXa0ifV6v63AVoDVq1cPKGudM5LRXLdqNNeV5tnIJtGTPAf4DPDWqnp0tqY9Yj1/A6tqR1VNVtXkxMTEfKQpSTqNkRSQJE+nUzw+WVWfbcKPJFneHF8OnGjiR4FVXaevBI4NK1dJUm+jeAorwEeBg1X1/q5Du4EtzfYW4Pau+OYkS5OsBdYB+4aVrySpt1HMgbwC+DfAvUnubmLvAN4H7EpyPfAQcB1AVR1Isgu4n84TXNuq6smhZy1J+nuGXkCq6v/Se14D4KrTnPNe4L0DS0qSdNb8JLokqRULiCSpFQuIJKkVC4gkqRULiCSpFQuIJKmVka6FJS1Ko1qDC1yHS/PKEYgkqRULiCSpFQuIJKkVC4gkqRUn0aXFxC/R0jxyBCJJasURiKTBc+RzTnIEIklqxQIiSWrFAiJJasUCIklqZcEUkCQbkxxKcjjJDaPOR5IWuwVRQJIsAf478FpgPfCvk6wfbVaStLgtlMd4NwCHq+o7AEluAzYB9480K0njbZQrH4/KEB9dXigFZAXwcNf+UeAfzWyUZCuwtdn9YZJDfbz3MuB7c85wcMxvbsxvbsxvboaf39kVzV75/Wy/Jy+UAtKrR55SZqtqB7DjrN44maqqybaJDZr5zY35zY35zc25nt+CmAOhM+JY1bW/Ejg2olwkSSycAvIXwLoka5M8A9gM7B5xTpK0qC2IW1hV9USS3wT+N7AEuLmqDszT25/VLa8RML+5Mb+5Mb+5OafzS7nYmCSphYVyC0uSNGYsIJKkVhZ1ARnH5VGSPJjk3iR3J5lqYhcl2ZPkgeb1wiHmc3OSE0nu64qdNp8k25v+PJTk6hHl954k32368O4krxtFfklWJflykoNJDiR5SxMfi/6bJb9x6b/zk+xLck+T339u4uPSf6fLbyz6r+uaS5J8I8kXmv3567+qWpQ/dCbjvw08H3gGcA+wfgzyehBYNiP2e8ANzfYNwH8ZYj6vBC4H7jtTPnSWmbkHWAqsbfp3yQjyew/wOz3aDjU/YDlwebP9XOAvmxzGov9myW9c+i/Ac5rtpwNfA64co/47XX5j0X9d1/1t4E+ALzT789Z/i3kE8pPlUarqcWB6eZRxtAnY2WzvBK4d1oWr6k7g+33mswm4rapOVdUR4DCdfh52fqcz1Pyq6nhVfb3Zfgw4SGdVhbHov1nyO51h51dV9cNm9+nNTzE+/Xe6/E5n6L8fSVYCvwx8ZEYe89J/i7mA9FoeZbZfnmEp4ItJ9jdLswBcUlXHofNLD1w8suxmz2ec+vQ3k3yzucU1PUQfWX5J1gAvo/O/1LHrvxn5wZj0X3P75W7gBLCnqsaq/06TH4xJ/wEfBN4G/LgrNm/9t5gLSF/Lo4zAK6rqcjorD29L8spRJ3QWxqVPbwJeAPw8cBz4b018JPkleQ7wGeCtVfXobE17xEaR39j0X1U9WVU/T2f1iQ1JXjJL83HJbyz6L8nrgRNVtb/fU3rEZs1vMReQsVwepaqONa8ngM/RGUI+kmQ5QPN6YnQZwiz5jEWfVtUjzS/2j4EP89Nh+NDzS/J0Ov84f7KqPtuEx6b/euU3Tv03rap+APwfYCNj1H+98huj/nsFcE2SB+ncon9Nkk8wj/23mAvI2C2PkuTZSZ47vQ38c+C+Jq8tTbMtwO2jyfAnTpfPbmBzkqVJ1gLrgH3DTm76l6PxBjp9OPT8kgT4KHCwqt7fdWgs+u90+Y1R/00keV6z/UzgF4FvMT791zO/cem/qtpeVSurag2df9/+vKreyHz236CfABjnH+B1dJ48+TbwzjHI5/l0noK4BzgwnRPwD4C9wAPN60VDzOlWOsPwv6PzP5TrZ8sHeGfTn4eA144ov48D9wLfbH4plo8iP+Cf0rkF8E3g7ubndePSf7PkNy79dxnwjSaP+4B3nen3YUzyG4v+m5Hrq/jpU1jz1n8uZSJJamUx38KSJM2BBUSS1IoFRJLUigVEktSKBUSS1IoFRJLUigVEktTK/wdZPHyFpXywgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_tweet = df['text'].str.len().plot.hist(color = 'red', figsize = (6, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab33fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4999.000000\n",
       "mean      107.402681\n",
       "std        50.913697\n",
       "min         6.000000\n",
       "25%        72.000000\n",
       "50%       108.000000\n",
       "75%       134.000000\n",
       "max       387.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_whole['length'] = df['text'].str.len()\n",
    "df_whole['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c0a5b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@marksandspencer @117241 @117244 @117242 @Tesco @sainsburys @117248 @AldiUK @117249 @Morrisons @117250 @117251 @117243 @117247 Imagine making your customers pay more than twice as much per pie for your top range and still only scoring a point higher than our basics. ;)\\n\\nJust you wait till our Deluxe mince pies get marked! And on that note, @117242 drop us a DM! https://t.co/8X2QAr23zN'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_whole[df_whole['length']==387]['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6580a5cf",
   "metadata": {},
   "source": [
    "# Changing the casing of the words\n",
    "\n",
    "play = Play = PLAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "805e6e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>@sprintcare i have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>@115712 please send us a private message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>@sprintcare i did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_lower  \n",
       "0  @115712 i understand. i would like to assist y...  \n",
       "1      @sprintcare and how do you propose we do that  \n",
       "2  @sprintcare i have sent several private messag...  \n",
       "3  @115712 please send us a private message so th...  \n",
       "4                                 @sprintcare i did.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_whole.iloc[:,5:6]\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df[\"text_lower\"] = df[\"text\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d040059",
   "metadata": {},
   "source": [
    "# Removal of Punctuations\n",
    "\n",
    "Okay = okay!\n",
    "\n",
    " The string.punctuation in python has the following symbols : \n",
    "\n",
    "(`@[\\\\]^_{|}~!\"#$%&<=>?\\'()*+,-./:;)\n",
    "\n",
    "maketrans(x,y,z) : It is used to construct the transition i.e specify the list of characters that need to be replaced in the whole string or the characters that need to be deleted from the string\n",
    "x : Specifies the list of characters that need to be replaced.\n",
    "y : Specifies the list of characters with which the characters need to be replaced.\n",
    "z : Specifies the list of characters that needs to be deleted.\n",
    "\n",
    "translate --> to do the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce73586e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>115712 I understand I would like to assist you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>sprintcare I have sent several private message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>115712 Please send us a Private Message so tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>sprintcare I did</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                       text_wo_punct  \n",
       "0  115712 I understand I would like to assist you...  \n",
       "1       sprintcare and how do you propose we do that  \n",
       "2  sprintcare I have sent several private message...  \n",
       "3  115712 Please send us a Private Message so tha...  \n",
       "4                                   sprintcare I did  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for clarity we remove the new column created in the last line\n",
    "df.drop([\"text_lower\"], axis=1, inplace=True)\n",
    "\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "df[\"text_wo_punct\"] = df[\"text\"].apply(lambda text: remove_punctuation(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f656d",
   "metadata": {},
   "source": [
    "Removal of stopwords such as 'a', 'an' and 'the'. They do not provide any valuable information and should be removed from the text\n",
    "\n",
    "These stopwords are already compiled in a list for different languages. In case of english it is the nltk package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c727b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f7ea4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'haven', 'into', 'more', 'with', 'here', 'when', 'at', 't', 'couldn', 'an', 'where', 'been', 'its', 'being', \"haven't\", \"should've\", 'me', 'we', 'against', 'yourselves', \"aren't\", 'whom', 'yourself', 'up', 'had', \"don't\", \"wouldn't\", 'himself', 'through', 'have', 'themselves', 'wasn', 'don', 'not', \"mustn't\", 'aren', 'do', \"it's\", 'while', 'most', \"you're\", 'once', 'y', 'those', 'further', 'yours', 'itself', 'is', 'if', 'above', 'and', 'him', 'between', 'before', \"needn't\", 're', 'own', 'of', 'theirs', 'it', 'can', 'that', 'than', 'or', 'does', 'too', 'about', 'these', 's', 'our', 'they', 'mightn', 'am', 'this', 'how', 'same', 'doesn', 'were', 'ma', 'then', 'all', 'ours', 'll', 'ain', 'in', 'isn', \"couldn't\", 'any', 'will', 'very', 'their', 'shouldn', 've', 'weren', 'myself', 'm', \"isn't\", \"weren't\", 'them', \"shan't\", 'are', \"hadn't\", 'as', \"didn't\", 'who', 'why', 'i', 'both', 'other', 'off', 'some', 'because', \"you'd\", 'a', 'from', 'on', 'ourselves', 'hers', 'won', 'has', 'down', 'mustn', 'under', 'my', \"shouldn't\", \"that'll\", 'herself', 'there', 'was', 'doing', 'until', 'out', 'so', 'your', 'now', 'again', 'what', 'did', \"she's\", 'hadn', 'after', 'having', 'shan', \"you've\", 'each', 'nor', 'you', 'her', 'such', 'by', 'his', 'during', 'over', \"mightn't\", 'wouldn', 'but', 'to', \"hasn't\", 'just', \"doesn't\", 'd', 'which', \"you'll\", 'only', 'o', 'hasn', 'needn', 'she', 'no', \"wasn't\", 'didn', 'should', 'the', 'be', 'he', 'below', 'for', \"won't\", 'few'}\n"
     ]
    }
   ],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "399a7b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>115712 I understand I would like to assist you...</td>\n",
       "      <td>115712 I understand I would like assist We wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>sprintcare I have sent several private message...</td>\n",
       "      <td>sprintcare I sent several private messages one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>115712 Please send us a Private Message so tha...</td>\n",
       "      <td>115712 Please send us Private Message assist J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>sprintcare I did</td>\n",
       "      <td>sprintcare I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  115712 I understand I would like to assist you...   \n",
       "1       sprintcare and how do you propose we do that   \n",
       "2  sprintcare I have sent several private message...   \n",
       "3  115712 Please send us a Private Message so tha...   \n",
       "4                                   sprintcare I did   \n",
       "\n",
       "                                        text_wo_stop  \n",
       "0  115712 I understand I would like assist We wou...  \n",
       "1                                 sprintcare propose  \n",
       "2  sprintcare I sent several private messages one...  \n",
       "3  115712 Please send us Private Message assist J...  \n",
       "4                                       sprintcare I  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df[\"text_wo_stop\"] = df[\"text_wo_punct\"].apply(lambda text: remove_stopwords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e612e062",
   "metadata": {},
   "source": [
    "Looking for the most common words and removing them from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d2e78f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 1437),\n",
       " ('us', 752),\n",
       " ('DM', 514),\n",
       " ('help', 479),\n",
       " ('Please', 376),\n",
       " ('We', 338),\n",
       " ('Hi', 293),\n",
       " ('Thanks', 287),\n",
       " ('get', 279),\n",
       " ('please', 247)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in df[\"text_wo_stop\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da6a0091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_wo_stopfreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>115712 I understand I would like to assist you...</td>\n",
       "      <td>115712 I understand I would like assist We wou...</td>\n",
       "      <td>115712 understand would like assist would need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>sprintcare propose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>sprintcare I have sent several private message...</td>\n",
       "      <td>sprintcare I sent several private messages one...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>115712 Please send us a Private Message so tha...</td>\n",
       "      <td>115712 Please send us Private Message assist J...</td>\n",
       "      <td>115712 send Private Message assist Just click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>sprintcare I did</td>\n",
       "      <td>sprintcare I</td>\n",
       "      <td>sprintcare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  115712 I understand I would like to assist you...   \n",
       "1       sprintcare and how do you propose we do that   \n",
       "2  sprintcare I have sent several private message...   \n",
       "3  115712 Please send us a Private Message so tha...   \n",
       "4                                   sprintcare I did   \n",
       "\n",
       "                                        text_wo_stop  \\\n",
       "0  115712 I understand I would like assist We wou...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare I sent several private messages one...   \n",
       "3  115712 Please send us Private Message assist J...   \n",
       "4                                       sprintcare I   \n",
       "\n",
       "                                    text_wo_stopfreq  \n",
       "0  115712 understand would like assist would need...  \n",
       "1                                 sprintcare propose  \n",
       "2  sprintcare sent several private messages one r...  \n",
       "3  115712 send Private Message assist Just click ...  \n",
       "4                                         sprintcare  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqwords = set([w for (w, wc) in cnt.most_common(10)])\n",
    "def remove_freqwords(text):\n",
    "    \"\"\"custom function to remove the frequent words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in freqwords])\n",
    "\n",
    "df[\"text_wo_stopfreq\"] = df[\"text_wo_stop\"].apply(lambda text: remove_freqwords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79debeff",
   "metadata": {},
   "source": [
    "Stemming : removes words which belong to the same group, like talk, talking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1df35d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"text_wo_punct\", \"text_wo_stop\"], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db3915f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_stopfreq</th>\n",
       "      <th>text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>115712 understand would like assist would need...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>@sprintcar and how do you propos we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "      <td>@sprintcar i have sent sever privat messag and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>115712 send Private Message assist Just click ...</td>\n",
       "      <td>@115712 pleas send us a privat messag so that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>@sprintcar i did.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@115712 Can you please send us a private messa...</td>\n",
       "      <td>115712 Can send private message gain details a...</td>\n",
       "      <td>@115712 can you pleas send us a privat message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>sprintcare worst customer service</td>\n",
       "      <td>@sprintcar is the worst custom servic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@115713 This is saddening to hear. Please shoo...</td>\n",
       "      <td>115713 This saddening hear shoot look KC</td>\n",
       "      <td>@115713 thi is sadden to hear. pleas shoot us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@sprintcare You gonna magically change your co...</td>\n",
       "      <td>sprintcare You gonna magically change connecti...</td>\n",
       "      <td>@sprintcar you gonna magic chang your connect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@115713 We understand your concerns and we'd l...</td>\n",
       "      <td>115713 understand concerns wed like send Direc...</td>\n",
       "      <td>@115713 we understand your concern and we'd li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "5  @115712 Can you please send us a private messa...   \n",
       "6          @sprintcare is the worst customer service   \n",
       "7  @115713 This is saddening to hear. Please shoo...   \n",
       "8  @sprintcare You gonna magically change your co...   \n",
       "9  @115713 We understand your concerns and we'd l...   \n",
       "\n",
       "                                    text_wo_stopfreq  \\\n",
       "0  115712 understand would like assist would need...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare sent several private messages one r...   \n",
       "3  115712 send Private Message assist Just click ...   \n",
       "4                                         sprintcare   \n",
       "5  115712 Can send private message gain details a...   \n",
       "6                  sprintcare worst customer service   \n",
       "7           115713 This saddening hear shoot look KC   \n",
       "8  sprintcare You gonna magically change connecti...   \n",
       "9  115713 understand concerns wed like send Direc...   \n",
       "\n",
       "                                        text_stemmed  \n",
       "0  @115712 i understand. i would like to assist y...  \n",
       "1        @sprintcar and how do you propos we do that  \n",
       "2  @sprintcar i have sent sever privat messag and...  \n",
       "3  @115712 pleas send us a privat messag so that ...  \n",
       "4                                  @sprintcar i did.  \n",
       "5  @115712 can you pleas send us a privat message...  \n",
       "6              @sprintcar is the worst custom servic  \n",
       "7  @115713 thi is sadden to hear. pleas shoot us ...  \n",
       "8  @sprintcar you gonna magic chang your connect ...  \n",
       "9  @115713 we understand your concern and we'd li...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "df[\"text_stemmed\"] = df[\"text\"].apply(lambda text: stem_words(text))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51746caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "SnowballStemmer.languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e00a09",
   "metadata": {},
   "source": [
    "Lemmatization : Similar to stemming, it reduces the words to their root stem but differs in the way that it makes sure the root word  belongs to the language.\n",
    "\n",
    "Slower than stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bf810f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_stopfreq</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>115712 understand would like assist would need...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>@sprintcar and how do you propos we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "      <td>@sprintcar i have sent sever privat messag and...</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>115712 send Private Message assist Just click ...</td>\n",
       "      <td>@115712 pleas send us a privat messag so that ...</td>\n",
       "      <td>@115712 Please send u a Private Message so tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>@sprintcar i did.</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                    text_wo_stopfreq  \\\n",
       "0  115712 understand would like assist would need...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare sent several private messages one r...   \n",
       "3  115712 send Private Message assist Just click ...   \n",
       "4                                         sprintcare   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0  @115712 i understand. i would like to assist y...   \n",
       "1        @sprintcar and how do you propos we do that   \n",
       "2  @sprintcar i have sent sever privat messag and...   \n",
       "3  @115712 pleas send us a privat messag so that ...   \n",
       "4                                  @sprintcar i did.   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  @115712 I understand. I would like to assist y...  \n",
       "1      @sprintcare and how do you propose we do that  \n",
       "2  @sprintcare I have sent several private messag...  \n",
       "3  @115712 Please send u a Private Message so tha...  \n",
       "4                                 @sprintcare I did.  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "df[\"text_lemmatized\"] = df[\"text\"].apply(lambda text: lemmatize_words(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7efeb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sleeping'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"sleeping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78bad1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sleep'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"sleeping\",\"v\") # v is for verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ea3aae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Word is : stripes\n",
      "Lemma result for verb :  strip\n",
      "Lemma result for noun :  stripe\n"
     ]
    }
   ],
   "source": [
    "print(\"The Word is : stripes\")\n",
    "print(\"Lemma result for verb : \",lemmatizer.lemmatize(\"stripes\", 'v'))\n",
    "print(\"Lemma result for noun : \",lemmatizer.lemmatize(\"stripes\", 'n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109da985",
   "metadata": {},
   "source": [
    "Removal of URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b984a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cdc2e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\tb\n",
      "c\td\n"
     ]
    }
   ],
   "source": [
    "s = 'a\\tb\\nc\\td'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0ac12e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\\tb\\nc\\td\n"
     ]
    }
   ],
   "source": [
    "s = r'a\\tb\\nc\\td'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48b89cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is my website,  check it out'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"This is my website, https://www.abc.com, check it out\"\n",
    "remove_urls(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a3de1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Want to learn more. Checkout  for additional information'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Want to learn more. Checkout www.h2o.ai for additional information\"\n",
    "remove_urls(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecee99e",
   "metadata": {},
   "source": [
    "# Please kill ur kernel and restart the code below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c00b538",
   "metadata": {},
   "source": [
    "The preparation stage consists of steps that clean up the data and cut out the extras. The steps are \n",
    "1. removing URLs and Twitter handles, \n",
    "2. making all text lowercase, \n",
    "3. removing numbers, \n",
    "4. removing punctuation, \n",
    "5. tokenization, \n",
    "6. removing stopwords, and \n",
    "7. stemming/lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6b53d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re  # used for preprocessing\n",
    "import nltk  # Natural Language Toolkit, used for preprocessing\n",
    "import string #used for preprocessing\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58bbb5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  tweet_id   author_id inbound                      created_at  \\\n",
       "0          0         1  sprintcare   False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1          1         2      115712    True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2          2         3      115712    True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3          3         4  sprintcare   False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4          4         5      115712    True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_whole = pd.read_csv(\"/home/mona/python_notebooks/data-visualization-main/twcs.csv\", nrows=5000)\n",
    "df = df_whole[[\"text\"]]\n",
    "df_whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55586ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @115712 I understand. I would like to assist y...\n",
       "1      @sprintcare and how do you propose we do that\n",
       "2  @sprintcare I have sent several private messag...\n",
       "3  @115712 Please send us a Private Message so th...\n",
       "4                                 @sprintcare I did."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_whole.iloc[:,5:6]\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8ff84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all urls\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "# make all text lowercase\n",
    "def text_lowercase(text):\n",
    "    return text.lower()\n",
    "# remove numbers\n",
    "def remove_numbers(text):\n",
    "    result = re.sub(r'\\d+', '', text)\n",
    "    return result\n",
    "# remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "# tokenize\n",
    "def tokenize(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "# remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    text = [i for i in text if not i in stop_words]\n",
    "    return text\n",
    "# lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(text):\n",
    "    text = [lemmatizer.lemmatize(token) for token in text]\n",
    "    return text\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = text_lowercase(text)\n",
    "    text = remove_urls(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = tokenize(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = lemmatize(text)\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef24d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_text_train = [] # our preprocessed text column\n",
    "for text_data in df['text']:\n",
    "    pp_text_data = preprocessing(text_data)\n",
    "    pp_text_train.append(pp_text_data)\n",
    "df['pp_text'] = pp_text_train # add the preprocessed text as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3447a20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pp_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>understand would like assist would need get pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>sprintcare sent several private message one re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>please send u private message assist click ‘ m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>sprintcare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                             pp_text  \n",
       "0  understand would like assist would need get pr...  \n",
       "1                                 sprintcare propose  \n",
       "2  sprintcare sent several private message one re...  \n",
       "3  please send u private message assist click ‘ m...  \n",
       "4                                         sprintcare  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e833741",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text_data = list(df['pp_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a3bde75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf=TfidfVectorizer()\n",
    "\n",
    "# the vectorizer must be fit onto the entire corpus\n",
    "fitted_vectorizer = tf.fit(final_text_data)\n",
    "\n",
    "transform_all = fitted_vectorizer.transform(df['pp_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e193af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5745)\t0.4456221575481119\n",
      "  (0, 5392)\t0.2971301363240985\n",
      "  (0, 4538)\t0.39872151996084854\n",
      "  (0, 3959)\t0.3477166153784154\n",
      "  (0, 3426)\t0.2149838498672251\n",
      "  (0, 2987)\t0.24521673893262155\n",
      "  (0, 2973)\t0.20097567623680238\n",
      "  (0, 2140)\t0.19313213598863382\n",
      "  (0, 375)\t0.49920770281839877\n",
      "  (1, 4826)\t0.5821845309552136\n",
      "  (1, 3997)\t0.8130566843194009\n",
      "  (2, 5485)\t0.44224804518192107\n",
      "  (2, 4826)\t0.34442562445916886\n",
      "  (2, 4593)\t0.3856751786145826\n",
      "  (2, 4568)\t0.2880742397499078\n",
      "  (2, 4311)\t0.4109520380961654\n",
      "  (2, 3959)\t0.3856751786145826\n",
      "  (2, 3589)\t0.2484298976069023\n",
      "  (2, 3232)\t0.27333351368254377\n",
      "  (3, 5230)\t0.36132675476387416\n",
      "  (3, 4561)\t0.2287878496512003\n",
      "  (3, 3979)\t0.3958127137465565\n",
      "  (3, 3959)\t0.37834209487323806\n",
      "  (3, 3837)\t0.1671200089543878\n",
      "  (3, 3232)\t0.5362729047650792\n",
      "  :\t:\n",
      "  (3996, 631)\t0.29508875108229626\n",
      "  (3996, 244)\t0.3477179960385903\n",
      "  (3997, 5100)\t0.3076793291715245\n",
      "  (3997, 3365)\t0.3829288990684415\n",
      "  (3997, 2250)\t0.49178082071284723\n",
      "  (3997, 2145)\t0.36012264035090025\n",
      "  (3997, 473)\t0.3081946256700988\n",
      "  (3997, 244)\t0.5405351696722\n",
      "  (3998, 4069)\t0.6345657032083282\n",
      "  (3998, 3963)\t0.4411946697586453\n",
      "  (3998, 244)\t0.6345657032083282\n",
      "  (3999, 5257)\t0.27803946203582736\n",
      "  (3999, 4852)\t0.32673845805564405\n",
      "  (3999, 4002)\t0.22493837276407547\n",
      "  (3999, 3837)\t0.12586350122966045\n",
      "  (3999, 3787)\t0.18073560863479057\n",
      "  (3999, 3705)\t0.3386247421207743\n",
      "  (3999, 3669)\t0.3386247421207743\n",
      "  (3999, 3528)\t0.18073560863479057\n",
      "  (3999, 3020)\t0.2888796793264695\n",
      "  (3999, 2633)\t0.22406849999052333\n",
      "  (3999, 2302)\t0.35537751858820676\n",
      "  (3999, 2250)\t0.2888796793264695\n",
      "  (3999, 1167)\t0.19333165742763656\n",
      "  (3999, 796)\t0.272126902859037\n"
     ]
    }
   ],
   "source": [
    "print(transform_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca39a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
